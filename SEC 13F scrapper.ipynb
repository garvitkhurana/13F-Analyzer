{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13554,
     "status": "ok",
     "timestamp": 1636404667939,
     "user": {
      "displayName": "Hak Song Lim",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "17976543482313788912"
     },
     "user_tz": 300
    },
    "id": "7nwKJw1Nf1tz",
    "outputId": "57e5eb11-1b11-4cc8-c897-5b9bc4ab1452"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sec_edgar_downloader\n",
      "  Downloading sec_edgar_downloader-4.2.2-py3-none-any.whl (13 kB)\n",
      "Collecting Faker\n",
      "  Downloading Faker-9.8.0-py3-none-any.whl (1.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.2 MB 8.2 MB/s \n",
      "\u001b[?25hRequirement already satisfied: bs4 in /usr/local/lib/python3.7/dist-packages (from sec_edgar_downloader) (0.0.1)\n",
      "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from sec_edgar_downloader) (4.2.6)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from sec_edgar_downloader) (2.23.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from bs4->sec_edgar_downloader) (4.6.3)\n",
      "Requirement already satisfied: text-unidecode==1.3 in /usr/local/lib/python3.7/dist-packages (from Faker->sec_edgar_downloader) (1.3)\n",
      "Requirement already satisfied: python-dateutil>=2.4 in /usr/local/lib/python3.7/dist-packages (from Faker->sec_edgar_downloader) (2.8.2)\n",
      "Collecting typing-extensions>=3.10.0.2\n",
      "  Downloading typing_extensions-3.10.0.2-py3-none-any.whl (26 kB)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.4->Faker->sec_edgar_downloader) (1.15.0)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->sec_edgar_downloader) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->sec_edgar_downloader) (1.24.3)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->sec_edgar_downloader) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->sec_edgar_downloader) (2021.5.30)\n",
      "Installing collected packages: typing-extensions, Faker, sec-edgar-downloader\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing-extensions 3.7.4.3\n",
      "    Uninstalling typing-extensions-3.7.4.3:\n",
      "      Successfully uninstalled typing-extensions-3.7.4.3\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow 2.6.0 requires typing-extensions~=3.7.4, but you have typing-extensions 3.10.0.2 which is incompatible.\u001b[0m\n",
      "Successfully installed Faker-9.8.0 sec-edgar-downloader-4.2.2 typing-extensions-3.10.0.2\n"
     ]
    }
   ],
   "source": [
    "!pip install sec_edgar_downloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4210,
     "status": "ok",
     "timestamp": 1636404672146,
     "user": {
      "displayName": "Hak Song Lim",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "17976543482313788912"
     },
     "user_tz": 300
    },
    "id": "iYRrdBHvf8ee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas_read_xml\n",
      "  Downloading pandas_read_xml-0.3.1-py3-none-any.whl (6.3 kB)\n",
      "Collecting xmltodict\n",
      "  Downloading xmltodict-0.12.0-py2.py3-none-any.whl (9.2 kB)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from pandas_read_xml) (1.1.5)\n",
      "Requirement already satisfied: pyarrow in /usr/local/lib/python3.7/dist-packages (from pandas_read_xml) (3.0.0)\n",
      "Collecting urllib3>=1.26.3\n",
      "  Downloading urllib3-1.26.7-py2.py3-none-any.whl (138 kB)\n",
      "\u001b[K     |████████████████████████████████| 138 kB 9.0 MB/s \n",
      "\u001b[?25hCollecting zipfile36\n",
      "  Downloading zipfile36-0.1.3-py3-none-any.whl (20 kB)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from pandas_read_xml) (2.23.0)\n",
      "Collecting distlib\n",
      "  Downloading distlib-0.3.3-py2.py3-none-any.whl (496 kB)\n",
      "\u001b[K     |████████████████████████████████| 496 kB 59.1 MB/s \n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from pandas->pandas_read_xml) (1.19.5)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->pandas_read_xml) (2018.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->pandas_read_xml) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->pandas_read_xml) (1.15.0)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->pandas_read_xml) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->pandas_read_xml) (2021.10.8)\n",
      "Collecting requests\n",
      "  Downloading requests-2.26.0-py2.py3-none-any.whl (62 kB)\n",
      "\u001b[K     |████████████████████████████████| 62 kB 892 kB/s \n",
      "\u001b[?25hRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->pandas_read_xml) (2.10)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests->pandas_read_xml) (2.0.7)\n",
      "Installing collected packages: urllib3, zipfile36, xmltodict, requests, distlib, pandas-read-xml\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 1.24.3\n",
      "    Uninstalling urllib3-1.24.3:\n",
      "      Successfully uninstalled urllib3-1.24.3\n",
      "  Attempting uninstall: requests\n",
      "    Found existing installation: requests 2.23.0\n",
      "    Uninstalling requests-2.23.0:\n",
      "      Successfully uninstalled requests-2.23.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.26.0 which is incompatible.\n",
      "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
      "Successfully installed distlib-0.3.3 pandas-read-xml-0.3.1 requests-2.26.0 urllib3-1.26.7 xmltodict-0.12.0 zipfile36-0.1.3\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas_read_xml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17650,
     "status": "ok",
     "timestamp": 1636404689789,
     "user": {
      "displayName": "Hak Song Lim",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "17976543482313788912"
     },
     "user_tz": 300
    },
    "id": "Fmb5nznDf-DY"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-e71807d8b8cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msec_edgar_downloader\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDownloader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas_read_xml\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpdx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mxml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0metree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mElementTree\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mET\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sec_edgar_downloader'",
      "",
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from sec_edgar_downloader import Downloader\n",
    "import pandas as pd\n",
    "import pandas_read_xml as pdx\n",
    "import xml.etree.ElementTree as ET\n",
    "import numpy as np\n",
    "from lxml import etree\n",
    "from bs4 import BeautifulSoup\n",
    "import glob\n",
    "from random import randint\n",
    "import time\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "71mwnL1igACF"
   },
   "outputs": [],
   "source": [
    "dl = Downloader('/content/drive/My Drive/Analytics in Practice APG/Data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1023,
     "status": "ok",
     "timestamp": 1636404690810,
     "user": {
      "displayName": "Hak Song Lim",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "17976543482313788912"
     },
     "user_tz": 300
    },
    "id": "-KhIxWXrgl0P"
   },
   "outputs": [],
   "source": [
    "scrap_list = pd.read_csv(\"/content/drive/My Drive/Analytics in Practice APG/Data/manager_list.csv\")\n",
    "scrap_list = list(scrap_list['CIK'])\n",
    "scrap_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 133718,
     "status": "ok",
     "timestamp": 1636404824527,
     "user": {
      "displayName": "Hak Song Lim",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "17976543482313788912"
     },
     "user_tz": 300
    },
    "id": "ZYJyTry8gqib"
   },
   "outputs": [],
   "source": [
    "filings = [\"13F-HR\"]\n",
    "for equity_id in scrap_list:\n",
    "    for i in filings:\n",
    "      try:\n",
    "        dl.get(i, equity_id, amount=1)\n",
    "        print(equity_id)\n",
    "      except:\n",
    "        time.sleep(20)\n",
    "        print('Error {}'.format(equity_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 106806,
     "status": "ok",
     "timestamp": 1636404931330,
     "user": {
      "displayName": "Hak Song Lim",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "17976543482313788912"
     },
     "user_tz": 300
    },
    "id": "Zf61FyKYg32-"
   },
   "outputs": [],
   "source": [
    "text_list = glob.glob(\"/content/drive/My Drive/Analytics in Practice APG/Data/sec-edgar-filings/*/13F-HR/*/full-submission.txt\")\n",
    "#text_list = glob.glob(\"/content/drive/My Drive/Analytics in Practice APG/Data/sec-edgar-filings/TWO SIGMA SECURITIES, LLC/13F-HR/*/full-submission.txt\")\n",
    "len(text_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "nJw1ZvPhC4XP"
   },
   "outputs": [],
   "source": [
    "for files in text_list:\n",
    "  try:\n",
    "    open_file = open(\"{}\".format(files),\"r\").read()\n",
    "    soup = BeautifulSoup(open_file, 'xml')\n",
    "    result = soup.find_all(\"XML\")\n",
    "    general_table = result[0]\n",
    "    investment_table = result[1]\n",
    "    removal_list = ['<XML>','</XML>']\n",
    "    for word in removal_list:\n",
    "      investment_table = str(investment_table).replace(word, \"\")\n",
    "    parser = etree.XMLParser(recover=True)\n",
    "    root = ET.fromstring(investment_table,parser)\n",
    "    tree = ET.ElementTree(root)\n",
    "    file_name = files[73:-48]\n",
    "    tree.write('/content/drive/My Drive/Analytics in Practice APG/Data/XML files/{}.xml'.format(file_name), encoding='utf-8', xml_declaration=True)\n",
    "    df = pdx.read_xml('/content/drive/My Drive/Analytics in Practice APG/Data/XML files/{}.xml'.format((file_name)), ['ns0:informationTable'])\n",
    "    df = pdx.fully_flatten(df)\n",
    "    df = df.rename(columns={'ns0:infoTable|ns0:nameOfIssuer':'NAME OF ISSUER',\n",
    "                            'ns0:infoTable|ns0:titleOfClass':'TITLE OF CLASS',\n",
    "                            'ns0:infoTable|ns0:cusip':'CUSIP',\n",
    "                            'ns0:infoTable|ns0:value':'VALUE (x$1000)',\n",
    "                            'ns0:infoTable|ns0:shrsOrPrnAmt|ns0:sshPrnamt':'SHRS OR PRN AMT',\n",
    "                            'ns0:infoTable|ns0:shrsOrPrnAmt|ns0:sshPrnamtType':'SH/PRN',\n",
    "                            'ns0:infoTable|ns0:investmentDiscretion':'INVESTMENT DISCRETION',\n",
    "                            'ns0:infoTable|ns0:otherManager':'OTHER MANAGER',\n",
    "                            'ns0:infoTable|ns0:putCall':'PUT/CALL',\n",
    "                            'ns0:infoTable|ns0:votingAuthority|ns0:Sole':'VOTING AUTHORITY SOLE',\n",
    "                            'ns0:infoTable|ns0:votingAuthority|ns0:Shared':'VOTING AUTHORITY SHARED',\n",
    "                            'ns0:infoTable|ns0:votingAuthority|ns0:None':'VOTING AUTHORITY NONE'})\n",
    "    df = df.drop(['@xmlns:ns0', '@xmlns:xsi', '@xsi:schemaLocation'], axis=1, errors='ignore')\n",
    "    df['NEW_CUSIP'] = '#' + df['CUSIP']\n",
    "    df.to_csv('/content/drive/My Drive/Analytics in Practice APG/Data/Excel files/{}.csv'.format(file_name), index=False)\n",
    "    print('GOOD {}'.format(file_name))\n",
    "  except Exception as e:\n",
    "    print(e)\n",
    "    print('Error {}'.format(file_name))\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "AjeAczJwV1aF"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "yjQi7PrNWaFD"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "SEC 13F scrapper.ipynb",
   "version": ""
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
